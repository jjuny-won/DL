{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 : 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것\n",
    "- 손실 함수의 결과값을 가장 작게 만드는 가중치 매개변수를 찾는 것이 학습 목표! \n",
    "\n",
    "## 4.1 데이터에서 학습 한다\n",
    "### 4.1.2 훈련 데이터와 시험 데이터\n",
    "- 모델의 범용 능력을 제대로 평가하기 위해 훈련 데이터와 시험 데이터로 분리한다\n",
    "- 훈련 데이터를 사용해 학습하며 최적의 매개변수를 찾는다\n",
    "- 시험 데이터를 사용해 훈련한 모델읠 실력을 평가한다\n",
    "- 오버피팅 : 한 데이터 셋에만 지나치게 최적화된 상태\n",
    "\n",
    "## 4.2 손실 함수\n",
    "- 신경망에서는 하나의 상태를 '지표'로 표기하고, 그 지표를 가장 좋게 만들어주는 가중치 매개변수의 값을 탐색한다\n",
    "- 손실 함수 : 평균 제곱 오차, 엔트로피 교차 오차 사용\n",
    "\n",
    "### 4.2.1 평균 제곱 오차 (MSE)\n",
    "- 원-핫 인코딩 : 한 원소만 1로 하고, 그 외는 0으로 나타내는 표기법\n",
    "- 평균 제곱 오차 : 각 원소의 출력 (추정값) 과 정답 레이블 (참 값)의 차를 제곱한 후 ,그 총함을 구한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def mean_squared_error(y,t):\n",
    "    return 0.5*np.sum((y-t)**2)\n",
    "\n",
    "t = [0,0,1,0,0,0,0,0,0,0]\n",
    "\n",
    "y = [0.1, 0.05, 0.6, 0.0,0.05, 0.1, 0.0 , 0.1, 0.0 , 0.0]\n",
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 교차 엔트로피 함수\n",
    "- 실질적으로 정담일 때 추정의 자연로그를 계산\n",
    "- 오차는 정답일 떄의 출력이 전체 값을 정함\n",
    "- 정답에 해당한는 출력이 커질 수록 0에 다가가다가, 출력이 1일 떄 0 이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t*np.log(y+delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [0,0,1,0,0,0,0,0,0,0]\n",
    "\n",
    "y = [0.1, 0.05, 0.6, 0.0,0.05, 0.1, 0.0 , 0.1, 0.0 , 0.0]\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 미니 배치 학습\n",
    "\n",
    "- 미니 배치 : 훈련 데이터 로부터 일부만 골라 학습을 수행하는 것\n",
    "- 미니 배치 학습 : 훈련 데이터에서 지정한 수를 무직위로 골라 학습시키는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train) , (x_test,t_test)= load_mnist(normalize = True, one_hot_label = True)\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 0\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23691, 15220, 51532, 52019,   619, 33955, 12326, 21000,  3955,\n",
       "       40356])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(60000, 10)\n",
    "#0 이상 100 미만인 수중에 무작위로 10개 고르는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5 왜 손실함수를 설명하는가?\n",
    "- 신경망 학습에서는 최적의 매개변수를 탐색할 때 손실 함수의 값을 가능한 한 작게 하는 매개변수 값 찾는다\n",
    "- 가중치 매개변수의 손실 함수의 미분 : 가중치 매개변수의 값을 아주 조금 변화 시켰을 때, 손실 함수가 어떻게 변화느냐\n",
    "\n",
    "- '정확도' 라고 표현하지 않는 이유 : 매개변수를 약간만 조정해서는 정확도 개선되지 않고 일정하게 유지되기 때문\n",
    "- 계단 함수 vs 시그모이드 함수 : 계단 함수는 한순가만 변화를 일으키지만, 시그모이드는 어떤 장소라도 0이 되지 않는다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 수치 미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 미분\n",
    "- 미분 : 한순간의 변화량을 표시한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f,x):\n",
    "    h = 10e-50\n",
    "    return (f(x+h)-f(x))/h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드에서 개선해야하는 점\n",
    "\n",
    "1. h를 0으로 무한히 보내고 싶어서 10e-50 이라는 값을 이용 -> 반올림 오차\n",
    "    - 작은 값이 생략되어 최종 계산 결과에 오차 발생\n",
    "    - 해결 방안 : 10**(-4)\n",
    "2. 함수 f 의 차분\n",
    "    - 이번 구현에서 미분은 (x+h)와 x 사이의 기울기에 해당\n",
    "    - h 를 무한히 0으로 좁히는 것이 불가능해 생기는 한계\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f,x):\n",
    "    h = 1e-4\n",
    "    return (f(x+h)-f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 수치 미분의 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(x):\n",
    "    return 0.01*x**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "x = np.arange(0.0 , 20.0, 0.1)\n",
    "y = func1(x)\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2999999999986347"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(func1, 5)\n",
    "numerical_diff(func1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 편미분\n",
    "\n",
    "- 변수가 여럿인 함수에 대한 미분\n",
    "- 편미분은 특정 장소의 기울기를 구하되, 여러 변수 중 목표 변수 하나에 초점을 맞추고 다른 변수 값은 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func_tmp1(x0):\n",
    "    return x0*x0 + 4.0**2.0\n",
    "\n",
    "numerical_diff(func_tmp1, 3.0)\n",
    "\n",
    "#x1을 4로 고정된 새로운 함수 정의하고 미분 함수 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기 (gradient)\n",
    "\n",
    "- 모든 변수의 편미분을 벡터로 정리한 것 \n",
    "- 기울기는 각 지점에서 낮아지는 방향을 가리킨다\n",
    "#### 기울기가 가리키는 쪽은 각 장소에서 함수의 출력 값을 가장 크게 줄이는 방향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f,x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val-h\n",
    "        fxh2= f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 경사법 ( 경사 하강법)\n",
    "- 경사법 : 현 위치에서 기울어진 방향으로 일정 거리만큼 이동\n",
    "  이동한 곳에서도 기울기를 구하고, 기울어진 방향으로 나아가기를 반복해서 함수의 값을 점차 줄이는 것\n",
    "  \n",
    "- 학습률 : 매개변수 값을 얼마나 갱신하느냐를 정하는 것 ( 0.01, 0.001 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr = 0.01 , step_num = 100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f,x)\n",
    "        x -= lr*grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0] ** 2 +x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x = init_x, lr = 0.1, step_num = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.58983747e+13, -1.29524862e+12])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습률이 큰 예시\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x = init_x, lr = 10.0, step_num = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.99999994,  3.99999992])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습률이 너무 작은 예시\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x = init_x, lr = 1e-10, step_num = 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼파라미터 : 사람이 직접 설정해야하는 매개변수     \n",
    "\n",
    "가중치 매개변수(가중치, 편향) : 훈련 데이터와 학습  알고리즘에 의해 '자동'으로 획득되는 매개변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 신경망에서의 기울기\n",
    "- w를 조금 변경했을 때 손실함수 L 이 얼마나 변화했느냐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append(os.pardir)\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "# 4.4.2 신경망에서의 기울기\n",
    "class simpleNet:\n",
    "    \"\"\"docstring for simpleNet\"\"\"\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2, 3)  # 정규분포로 초기화\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def f(w):\n",
    "    return net.loss(x,t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.27362602  0.45117513 -0.3841255 ]\n",
      " [ 0.28726657  0.48085954 -2.06419377]]\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.42271552  0.70347866 -2.08824969]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.388652225524378"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)\n",
    "np.argmax(p)\n",
    "\n",
    "t  = np.array([0,0,1])\n",
    "net.loss(x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24944605  0.33030147 -0.57974752]\n",
      " [ 0.37416907  0.4954522  -0.86962127]]\n"
     ]
    }
   ],
   "source": [
    "f = lambda w : net.loss(x,t)\n",
    "dW = numerical_gradient(f, net.W)\n",
    "# dW = numerical_gradient(f,net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 학습 알고리즘 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전제\n",
    "신경망에는 가중치, 편향이 있고, 이 가중치과 편향을 훈련 데이터에 적응하도록 조정하는 과정이 '학습'\n",
    "\n",
    "- 학습 단계\n",
    "1. 미니 배치  : 훈련 데이터 중 일부를 무작위로 가져와서 선별한 데이터 ( 확률적 경사 하강법 ) -> 미니 배치        \n",
    "    우리는 미니 배치의 손실 함수의 값을 줄이는 것이 목표!\n",
    "\n",
    "2. 기울기 산출 : 미니 배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구한다.      \n",
    "    기울기는 손실 함수 값을 가장 작게하는 방향을 제시\n",
    "\n",
    "3. 매개변수 갱신 : 가중치 매개변수를 기울기 방향으로 아주 조금 갱신\n",
    "    \n",
    "4. 반복 : 1~3 단계 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 2층 신경망 클래스 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append(os.pardir)\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01 ):\n",
    "    \n",
    "        #가중치 초기화 \n",
    "        self.params= {} # 신경망의 매개변수를 보관하는 딕셔너리 변수 \n",
    "        self.params['W1'] = weight_init_std *np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std *np.random.randn(input_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x,W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(x,W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def loss(self,x,t): # predict 의 결과와 정답 레이블 바탕으로 교차 엔트로피 오차 구하도록 구현\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y,t)\n",
    "    \n",
    "    def accuracy(self, x,t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y==t) /float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self,x,t): # 각 매개변수의 기울기 계산\n",
    "        loss_W = lambda W : self.loss(x,t)\n",
    "         \n",
    "        grads ={} #기울기는 보관하는 딕셔너리 변수\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TwoLayerNet(input_size= 784, hidden_size=100, output_size=10)\n",
    "\n",
    "x = np.random.rand(100,784)\n",
    "y = net.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2 미니 배치 학습 구현하기\n",
    "- 미니 배치 학습 : 훈련 데이터 중 일부를 무작위로 꺼내고, 그 미니 배치에 대하여 경사법으로 매개변수를 갱신하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "\n",
    "# 4.5.2 미니배치 학습 구현하기\n",
    "# * 주의 : 아주 오래 걸림 *\n",
    "\"\"\"\n",
    "60000개의 훈련 데이터에서 임의로 100개의 데이터(이미지&정답 레이블)을 추려냄.\n",
    "100개의 미니배치를 대상으로 확률적 경사 하강법을 수행해 매개변수를 갱신한다.\n",
    "경사법에 의한 갱신 횟수를 1000번으로 설정하고 갱신할 때마다 손실 함수를 계산한다.\n",
    "\"\"\"\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=False)\n",
    "\n",
    "# 하이퍼 파라메터\n",
    "iters_num = 1000  # 반복횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100  # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    print(i)\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    # 기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = network.gradient(x_batch, t_batch)  # 다음 장에서 구현할 더 빠른 방법!\n",
    "\n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.3 시험 데이터로 평가하기\n",
    "\n",
    "- 손실 함수의 값 : '훈련 데이터의 미니배치에 대한 손실함수'\n",
    "- 훈련 데이터 외의 다른 데이터도 올바르게 인식하는지 확인 필요 -> '오버피팅' 확인 필요\n",
    "    - 훈련데이터 이미지만 제대로 구분하고 , 그렇지 않은 것은 식별할 수 X\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 에폭\n",
    "- 학습에서 훈련 데이터를 모두 소진했을 때의 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
